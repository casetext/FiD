{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50bf900d-2f90-4bd3-9002-e5bff7e5c4bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "051e6be8-705f-4144-8de5-b875a61fcd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "import transformers\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "import argparse\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from rouge_score import rouge_scorer\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "import seaborn as sns\n",
    "from itertools import count\n",
    "from scipy.signal import find_peaks\n",
    "from findpeaks import findpeaks\n",
    "import scipy.signal\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47371a17-4b5d-4d76-b8d9-84be8931b5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/divy/FiD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5550822f-9127-4a09-a2b7-459f7a261be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src\n",
    "from src.data import load_data\n",
    "from src.evaluation import ems\n",
    "import src.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdeecc9-5bda-49e8-a7cd-357f75582f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a2dcfff-9a85-42a2-9bc7-630e8380468e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5643fc-1da6-4463-b210-f202c713aa7a",
   "metadata": {},
   "source": [
    "Try out NQ with NQ pretrained checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e47f4595-c41c-47d0-b3c0-34b9a9cba9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "nq_path =  \"/mnt/disks/external_mounted_disk/datasets/NQ/NQ/dev.json\"\n",
    "compose_path = \"/mnt/disks/external_mounted_disk/datasets/compose_FiD/compose_fid_qa/dev.json\"\n",
    "control_path = \"/mnt/disks/external_mounted_disk/datasets/compose_FiD/compose_fid_qa/control.json\"\n",
    "control_copy_path = \"/mnt/disks/external_mounted_disk/datasets/compose_FiD/compose_fid_qa/control_copy.json\"\n",
    "\n",
    "\n",
    "one_correct_path = \"/mnt/disks/external_mounted_disk/datasets/compose_FiD/compose_fid_qa/one_correct.json\"\n",
    "none_correct_path = \"/mnt/disks/external_mounted_disk/datasets/compose_FiD/compose_fid_qa/none_correct.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03358bdf-f635-4c32-97af-64598b352a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncorrupted examples\n",
    "eval_examples = load_data(\n",
    "                            compose_path,\n",
    "                            global_rank=0,\n",
    "                            world_size=1,\n",
    "                            )\n",
    "\n",
    "\n",
    "# examples with 4 nonsensical support, one correct\n",
    "one_correct_examples = load_data(\n",
    "                            one_correct_path,\n",
    "                            global_rank=0,\n",
    "                            world_size=1,\n",
    "                            )\n",
    "\n",
    "# all 5 support passages are nonsensical\n",
    "none_correct_examples = load_data(\n",
    "                            none_correct_path,\n",
    "                            global_rank=0,\n",
    "                            world_size=1,\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca36a4b2-4d3d-424b-9d03-bd742424eac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting to 5 so as to keep it short for testing\n",
    "n_passages = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f16c95ae-0fa7-4b31-bf78-6c06357ab8fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset_dev = src.data.Dataset(eval_examples, n_passages)\n",
    "sampler_dev = SequentialSampler(eval_dataset_dev)\n",
    "len(eval_dataset_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2e30b9b-40af-4973-bc74-5d4c0d92a9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_correct_dataset = src.data.Dataset(one_correct_examples, n_passages)\n",
    "sampler_one_correct = SequentialSampler(one_correct_dataset)\n",
    "len(one_correct_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03016da3-de81-449c-993b-c14676173aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "none_correct_dataset = src.data.Dataset(none_correct_examples, n_passages)\n",
    "sampler_none_correct = SequentialSampler(none_correct_dataset)\n",
    "len(none_correct_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5ace3c7-3068-4574-9dae-dbadf91f5f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.T5Tokenizer.from_pretrained('t5-base')\n",
    "collator = src.data.Collator(200, tokenizer, answer_maxlength=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ea37eb3-8337-4a5d-9dd0-1de9e8ef5992",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_dev = DataLoader(eval_dataset_dev,\n",
    "        sampler=sampler_dev,\n",
    "        batch_size=1,\n",
    "        drop_last=False,\n",
    "        num_workers=10,\n",
    "        collate_fn=collator\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "926b0726-13c5-446a-9b35-4dcbac666bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_oc = DataLoader(one_correct_dataset,\n",
    "        sampler=sampler_one_correct,\n",
    "        batch_size=1,\n",
    "        drop_last=False,\n",
    "        num_workers=10,\n",
    "        collate_fn=collator\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b1c555f-128d-493f-934a-0a20307740c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_nc = DataLoader(none_correct_dataset,\n",
    "        sampler=sampler_none_correct,\n",
    "        batch_size=1,\n",
    "        drop_last=False,\n",
    "        num_workers=10,\n",
    "        collate_fn=collator\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac1095f-8d4f-4efd-9724-e1f42a5e2a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "212013b8-a939-48f8-b484-f6c55b8cb7ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96036544-f6de-40a2-b36e-4bdd00951c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 't5-base'\n",
    "model_class = src.model.FiDT5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1f0b666-335b-4461-bb9c-820e2e0d30cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = \"/home/divy/FiD/model_ckpts/test_experiment_large_fid_qa_compose\"\n",
    "model = model_class.from_pretrained(load_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65cbcb66-00ea-447d-b253-0405630114fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda692ca-5547-4f5f-aceb-dedc4f8281eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68f6978d-6e27-4c24-a2e3-5e974ead8b29",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### load an example input, generated output and ground truth output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "384e8bc8-61b6-4ac5-8218-3a56340f9daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cherry_picked_example = 1\n",
    "scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23500cc4-5018-4d49-80b8-b8feedbb28d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,   156,    46,  3490,  1854,  2897,     3,     9,  1137,    13,\n",
      "          1041,   365,  8100,   205,     3,     2,  2596,  4327,    21,  3338,\n",
      "            12,   726,  2559, 15488,     6,     8,  3490,   164,    36,  7201,\n",
      "            12,  8303,    73, 12760, 15488,     6,  1046,     6,  4360,  4917,\n",
      "          3051,     6,    11,  1358,     6,    38,   168,    38,     8,   423,\n",
      "           866,    13,     8,  2559, 11458,    42, 22624,   788,     6,    38,\n",
      "           168,    38,  4360,  4917,  3051,    11,  1358,     5,     1]],\n",
      "       device='cuda:0')\n",
      "[-1.5983444, -1.6664832, -1.6664832, -1.2532346, -1.5556364, -1.6425496, -1.6425496, -1.1384568, -1.8597382, -1.714814, -0.50836825, 0.6989463, -0.36014405]\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(dataloader_dev):\n",
    "    (idx, labels, _, context_ids, context_mask) = batch\n",
    "    \n",
    "    if i == cherry_picked_example:\n",
    "        \n",
    "        generated_output, log_prob = model.generate(\n",
    "                input_ids=context_ids.cuda(),\n",
    "                attention_mask=context_mask.cuda(),\n",
    "                do_sample=False,\n",
    "                max_length=150,\n",
    "                top_p=0.9,\n",
    "                temperature=1.0,\n",
    "                output_confidence=True,\n",
    "\n",
    "            )\n",
    "        \n",
    "        print(generated_output)\n",
    "        \n",
    "        input_scores = model.obtain_input_scores(\n",
    "            generated_output.cuda(),\n",
    "            context_ids.cuda(),\n",
    "            context_mask.cuda(),\n",
    "            tokenizer\n",
    "        )\n",
    "        \n",
    "        print(input_scores)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7d8747d-e766-428a-a76f-71058148f089",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([75])\n",
      "torch.Size([1, 12, 176])\n",
      "====\n",
      "0\n",
      "question: What does the plaintiff have to establish when the defendant's allegedly extreme and outrageous conduct was directed towards someone other than the plaintiff? title: context: The plaintiff must show that the defendant's conduct was extreme and outrageous.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "====\n",
      "1\n",
      "question: What does the plaintiff have to establish when the defendant's allegedly extreme and outrageous conduct was directed towards someone other than the plaintiff? title: context: Second, the plaintiff must prove that the defendant's conduct was extreme and outrageous.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "====\n",
      "2\n",
      "question: What does the plaintiff have to establish when the defendant's allegedly extreme and outrageous conduct was directed towards someone other than the plaintiff? title: context: First, the plaintiff must establish that the defendant's conduct was extreme and outrageous.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "====\n",
      "3\n",
      "question: What does the plaintiff have to establish when the defendant's allegedly extreme and outrageous conduct was directed towards someone other than the plaintiff? title: context: The plaintiff must first show that there was extreme and outrageous conduct.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "====\n",
      "4\n",
      "question: What does the plaintiff have to establish when the defendant's allegedly extreme and outrageous conduct was directed towards someone other than the plaintiff? title: context: (2) The plaintiff must prove that the defendant's conduct was extreme and outrageous.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "====\n",
      "5\n",
      "question: What does the plaintiff have to establish when the defendant's allegedly extreme and outrageous conduct was directed towards someone other than the plaintiff? title: context: To recover on such a claim, the plaintiff must show that the defendant's conduct was extreme and outrageous.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "====\n",
      "6\n",
      "question: What does the plaintiff have to establish when the defendant's allegedly extreme and outrageous conduct was directed towards someone other than the plaintiff? title: context: First, the plaintiff must demonstrate that the defendant engaged in \"extreme and outrageous\" conduct.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "====\n",
      "7\n",
      "question: What does the plaintiff have to establish when the defendant's allegedly extreme and outrageous conduct was directed towards someone other than the plaintiff? title: context: First, the plaintiff must demonstrate that the defendant engaged in \"extreme and outrageous\" conduct.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "====\n",
      "8\n",
      "question: What does the plaintiff have to establish when the defendant's allegedly extreme and outrageous conduct was directed towards someone other than the plaintiff? title: context: First, the plaintiff must demonstrate that the defendant engaged in \"extreme and outrageous\" conduct.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "====\n",
      "9\n",
      "question: What does the plaintiff have to establish when the defendant's allegedly extreme and outrageous conduct was directed towards someone other than the plaintiff? title: context: Additionally, the plaintiff must show that the defendant's conduct was \"outrageous.\"</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "====\n",
      "10\n",
      "question: What does the plaintiff have to establish when the defendant's allegedly extreme and outrageous conduct was directed towards someone other than the plaintiff? title: context: This tort [intentional infliction of emotional distress] requires, inter alia, intentional extreme and outrageous conduct on the part of the tortfeasor, which causes severe emotional distress to the plaintiff. See, e.g., Hoy v. Angelone, 554 Pa. 134, 720 A.2d 745, 754 (1998). However, 'where such conduct is directed at a third person' the person claiming the emotional distress must also establish that he is a member of the victim's immediate family and that he or she was 'present at the time' of the tortious conduct.</s>\n",
      "====\n",
      "11\n",
      "question: What does the plaintiff have to establish when the defendant's allegedly extreme and outrageous conduct was directed towards someone other than the plaintiff? title: context: This tort [intentional infliction of emotional distress] requires, inter alia, intentional extreme and outrageous conduct on the part of the tortfeasor, which causes severe emotional distress to the plaintiff. See, e.g., Hoy v. Angelone, 554 Pa. 134, 720 A.2d 745, 754 (1998). However, 'where such conduct is directed at a third person' the person claiming the emotional distress must also establish that he is a member of the victim's immediate family and that he or she was 'present at the time' of the tortious conduct.</s>\n",
      "\n",
      "\n",
      "generated answer:\n",
      "When the defendant's allegedly extreme and outrageous conduct was directed towards someone other than the plaintiff, the plaintiff must also establish that they were a member of the victim's immediate family and that they were present at the time of the tortious conduct.\n",
      "\n",
      "\n",
      "ground truth answer:\n",
      "When the defendant's allegedly extreme and outrageous conduct was directed towards someone other than the plaintiff, the plaintiff must also establish that they are a member of the victim's immediate family and that they were present at the time of the tortious conduct.\n",
      "53\n",
      "\n",
      "log_prob\n",
      "0.021109695\n",
      "\n",
      "rouge score\n",
      "0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(dataloader_dev):\n",
    "    (idx, labels, _, context_ids, context_mask) = batch\n",
    "    \n",
    "    if i == cherry_picked_example:\n",
    "        \n",
    "        print(idx)\n",
    "        print(context_ids.shape)\n",
    "        \n",
    "        for j in range(context_ids.shape[1]):\n",
    "\n",
    "            print(\"====\")\n",
    "            print(j)\n",
    "            context = tokenizer.decode(context_ids[0][j])\n",
    "            print(context)\n",
    "            \n",
    "            \n",
    "        print(\"\")\n",
    "        print(\"\")\n",
    "        print(\"generated answer:\")\n",
    "        # generated_output = model.generate(\n",
    "        #         input_ids=context_ids.cuda(),\n",
    "        #         attention_mask=context_mask.cuda(),\n",
    "        #         max_length=50\n",
    "        #     ).cpu()\n",
    "        \n",
    "        generated_output, log_prob = model.generate(\n",
    "                input_ids=context_ids.cuda(),\n",
    "                attention_mask=context_mask.cuda(),\n",
    "                do_sample=False,\n",
    "                max_length=150,\n",
    "                top_p=0.9,\n",
    "                temperature=1.0,\n",
    "                output_confidence=True,\n",
    "                \n",
    "            )\n",
    "        \n",
    "        # generated_output = generated_output.cpu()\n",
    "        \n",
    "        # print(generated_output.sequences)\n",
    "        # print(generated_output.scores)\n",
    "        \n",
    "        # print(generated_output)\n",
    "        # print(len(generated_output[0]))\n",
    "        \n",
    "        human_readable_generated_output = tokenizer.decode(generated_output[0], skip_special_tokens=True)\n",
    "        print(human_readable_generated_output)\n",
    "        \n",
    "        print(\"\")\n",
    "        print(\"\")\n",
    "        print(\"ground truth answer:\")\n",
    "        ground_truth_answer = tokenizer.decode(labels[0], skip_special_tokens=True)\n",
    "        print(ground_truth_answer)\n",
    "        print(len(labels[0]))\n",
    "        \n",
    "        print(\"\")\n",
    "        print(\"log_prob\")\n",
    "        print(log_prob)\n",
    "        \n",
    "        print(\"\")\n",
    "        print(\"rouge score\")\n",
    "        rouge_score = scorer.score(ground_truth_answer, human_readable_generated_output)['rougeL'].fmeasure\n",
    "        print(rouge_score)\n",
    "        break\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab05c654-5b06-48bf-a17e-d8958efcf1fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "664f7ee5-85d2-4281-9061-349867efbb45",
   "metadata": {
    "tags": []
   },
   "source": [
    "## compute g_{q,p} / max-pool attention matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b1cbbc-2aef-4b8f-bcfb-a6c0321f76da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "045bcb00-f38a-47cb-9f3b-a2037a811c83",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Compute a potential score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8a963c6-6d8b-4fce-9e60-63613a40cc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subfinder(mylist, pattern):\n",
    "    matches = []\n",
    "    for i in range(len(mylist)):\n",
    "        if mylist[i] == pattern[0] and mylist[i:i+len(pattern)] == pattern:\n",
    "            matches.append((i + len(pattern), pattern))\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5091ea8-eebf-43b4-ac94-7876a23db6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../numpy_drops/rouge_similarity_answers_dev_v2\", \"rb\") as f:\n",
    "    rouge_matches = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a381d4ed-519c-4eea-84b5-160cb87bc6af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('If a plaintiff experiences a continuing practice and policy of discrimination, the commencement of the statute of limitations period may be delayed until the last discriminatory act in furtherance of the continuous practice or policy.',\n",
       "  'Under the continuing violation doctrine, if a plaintiff has experienced a continuing practice and policy of discrimination, the commencement of the statute of limitations period may be delayed until the last discriminatory act in furtherance of the policy or practice.',\n",
       "  0.8266666666666667,\n",
       "  array(0.00294728, dtype=float32),\n",
       "  0),\n",
       " ('An employee alleging a cause of action under Lab C 1197 for failure to pay minimum wages may be entitled to recover: (1) the unpaid minimum wages, interest, reasonable attorney fees, and the costs of suit (Lab C 1194(a)); (2) liquidated damages in an amount equal to the unpaid wages and interest (Lab C 1194.2(a)); and (3) a civil penalty, plus a late payment penalty if the employee was separated from employment (Lab C 1197.1(a)).',\n",
       "  'If an employee alleges a cause of action under Lab C $1197 for failure to pay minimum wages, the employee may be entitled to recover unpaid wages, interest, reasonable attorney fees, and costs, as well as interest and penalties.',\n",
       "  0.5546218487394958,\n",
       "  array(0.09707894, dtype=float32),\n",
       "  1),\n",
       " ('An arbitration agreement that gives one party the sole power to select the arbitrator is substantively unconscionable.',\n",
       "  'An arbitration agreement that gives one party the sole power to select the arbitrator is substantively unconscionable.',\n",
       "  1.0,\n",
       "  array(0., dtype=float32),\n",
       "  2),\n",
       " ('Under FEHA, \"medical condition\" means either: (1) a health impairment relating to a diagnosis of cancer for which a person has been cured; or (2) genetic characteristics or information that is known to cause or increase the risk of a particular disease or disorder and presently not associated with any symptoms of any disease or disorder.',\n",
       "  'Under FEHA, a \"medical condition\" means either of the following: (1) any health impairment related to or associated with a diagnosis of cancer or a record or history of cancer; or (2) genetic characteristics.',\n",
       "  0.4444444444444445,\n",
       "  array(0., dtype=float32),\n",
       "  3),\n",
       " ('The responding party may choose to produce documents in lieu of written answers to the interrogatories only if answers to the interrogatories can actually be derived from the responding party’s production of business records.',\n",
       "  'Answers to interrogatories can be derived from the responding party’s production of business records, if an unequal burden exists between the parties.',\n",
       "  0.5172413793103448,\n",
       "  array(0.14347161, dtype=float32),\n",
       "  4),\n",
       " ('An assignment of rights must be valued at the time of settlement, so that a price can be set as part of the good faith determination process.',\n",
       "  'Because an assignment of rights can be a valuable asset in settlement of claims, it must be valued at the time of settlement so that a price can be set as part of the good faith determination process.',\n",
       "  0.8307692307692308,\n",
       "  array(0.01522516, dtype=float32),\n",
       "  5),\n",
       " ('If an employee with a disability is not qualified for any current vacancies, an employer is not required to provide the employee with an indefinite leave of absence to await possible future vacancies to which the employee could potentially be reassigned.',\n",
       "  'An employer is not required to provide an indefinite leave of absence if an employee with a disability is not qualified for any current vacancies.',\n",
       "  0.3939393939393939,\n",
       "  array(0., dtype=float32),\n",
       "  6),\n",
       " ('28 U.S.C.  1631, entitled “Transfer to cure want of jurisdiction,” provides that whenever a civil action is filed, and the court finds that there is “a want of jurisdiction,” the court “shall, if it is in the interest of justice, transfer such action or appeal to any other such court (or, for cases within the jurisdiction of the United States Tax Court, to that court) in which the action or appeal could have been brought at the time it was filed or noticed.”',\n",
       "  'If a civil action is filed in a court and that court finds that it lacks subject matter jurisdiction, the court \"shall, if it is in the interest of justice, transfer such action or appeal to any other such court (or, for cases within the jurisdiction of the United States Tax Court, to that court) in which the action or appeal could have been brought at the time it was filed or noticed, and the action or appeal shall proceed as if it had been filed in or noticed for the court to which it is transferred on the date it was actually filed in or noticed for the court',\n",
       "  0.6564102564102564,\n",
       "  array(0.06192256, dtype=float32),\n",
       "  7),\n",
       " ('Priority of timing is determined by filing date, not date of service.',\n",
       "  'Priority of timing is determined by the date that the complaint is filed, not the date that the complaint is served.',\n",
       "  0.5454545454545454,\n",
       "  array(0.07271203, dtype=float32),\n",
       "  8),\n",
       " ('Certain exceptions to application of the “ABC” test exist, wherein courts must apply the Borello standard, including if the worker is covered by an exception expressly made by the Labor Code or an Industrial Welfare Commission order, as well as occupations specifically listed in the statute such as certain insurance, health care, professional services, investment, fishing, and media positions.',\n",
       "  'The “ABC” test is an irrational test that considers only the employee’s right to control his or her job. If there are any exceptions to the test, the determination of whether an employee is an employee or an independent contractor will be based on the “ABC” test.',\n",
       "  0.205607476635514,\n",
       "  array(0.24814771, dtype=float32),\n",
       "  9)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_matches[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25e0cb6d-5a8a-4852-a7c3-a76c9b704620",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_rouge_similarities = [el for el in rouge_matches if el[2] >= 0.9]\n",
    "high_rouge_similarity_indices = [el[3] for el in high_rouge_similarities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b88a823-e0e2-4395-b458-d7f0a77d821b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_rouge_similarities = [el for el in rouge_matches if el[2] <= 0.3]\n",
    "low_rouge_similarity_indices = [el[3] for el in low_rouge_similarities]\n",
    "\n",
    "len(low_rouge_similarity_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "adcfc6a0-637d-41ec-b6a5-f2e78da8b81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_savgols_low_similarity = []\n",
    "max_savgols_low_similarity = []\n",
    "\n",
    "min_savgols_high_similarity = []\n",
    "max_savgols_high_similarity = []\n",
    "\n",
    "passage_max_scores = []\n",
    "passage_mean_scores = []\n",
    "\n",
    "rouge_scores = []\n",
    "log_probs = []\n",
    "\n",
    "# set criterion on the number of passages that must be used\n",
    "topk_passages = 5\n",
    "topk_passage_means = []\n",
    "topk_passage_stdevs = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5e02a1e-c443-4f32-9a4d-794b7e60a580",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:02,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(30, 88), (230, 271), (430, 476), (630, 690), (830, 884), (1030, 1070), (1230, 1285), (1430, 1482), (1630, 1684), (1830, 1888), (2030, 2199), (2230, 2312), (2430, 2599), (2630, 2712)]\n",
      "[0.09722672, 0.035961956, 1.385124, 0.8521029, 1.0795133, 0.42338902, 0.95472276, 1.4571953, 1.2572294, 1.0908605, -1.2826912, -1.2958845, -1.2826912, -1.2958845]\n",
      "1.4571953 -1.2958845\n",
      "0.8266666666666667\n",
      "[1.0795133 1.0908605 1.2572294 1.385124  1.4571953]\n",
      "0.15202127\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:05,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(36, 59), (236, 261), (436, 461), (636, 657), (836, 863), (1036, 1059), (1236, 1259), (1436, 1472), (1636, 1675), (1836, 1867), (2036, 2098), (2236, 2307), (2436, 2599)]\n",
      "[-1.5983444, -1.6664832, -1.6664832, -1.2532346, -1.5556364, -1.6425496, -1.6425496, -1.1384568, -1.8597382, -1.714814, -0.50836825, 0.6989463, -0.36014405]\n",
      "0.6989463 -1.8597382\n",
      "0.5074626865671642\n",
      "[-1.2532346  -1.1384568  -0.50836825  0.6989463  -0.36014405]\n",
      "0.69732934\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:06,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(30, 79), (135, 167), (240, 267), (345, 372), (450, 482), (555, 629), (660, 695), (765, 792), (870, 905), (975, 1037), (1080, 1146), (1185, 1241), (1290, 1351), (1395, 1461), (1500, 1561), (1605, 1671), (1710, 1776), (1815, 1871)]\n",
      "[-1.506421, -1.857425, -1.5619498, -2.0615804, -1.9215717, -1.2851454, -1.159129, -1.4848357, -1.7595612, -1.4084375, -1.5848768, -1.005441, -1.006616, -1.5848768, -1.006616, -1.5848768, -1.5848768, -1.005441]\n",
      "-1.005441 -2.0615804\n",
      "1.0\n",
      "[-1.159129 -1.006616 -1.006616 -1.005441 -1.005441]\n",
      "0.061242476\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:09,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(19, 54), (219, 276), (419, 471), (619, 639), (819, 840), (1019, 1051), (1219, 1259), (1419, 1455), (1619, 1659), (1819, 1860), (2019, 2199), (2219, 2399)]\n",
      "[-0.806493, -1.1690782, -1.314888, -1.2788199, -0.9131406, -1.7853014, -1.7238843, -2.0996246, -1.8583053, -1.1964879, -0.0778188, -0.0699618]\n",
      "-0.0699618 -2.0996246\n",
      "0.4444444444444445\n",
      "[-1.1690782 -0.9131406 -0.806493  -0.0778188 -0.0699618]\n",
      "0.45119703\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:11,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(27, 57), (156, 185), (285, 325), (414, 450), (543, 579), (672, 737), (801, 884), (930, 984), (1059, 1092), (1188, 1238), (1317, 1391), (1446, 1494), (1575, 1640), (1704, 1767), (1833, 1914), (1962, 2063), (2091, 2118), (2220, 2294), (2349, 2397), (2478, 2560)]\n",
      "[-1.0082282, -0.42948732, -0.70434517, -0.9272571, -0.9272571, -0.30211803, -0.6080733, -1.2066728, -1.0369202, -0.5656351, -0.18483634, 0.49038443, -0.2916806, -0.23003814, 0.09089057, -0.37091047, -0.1149813, -0.16647543, 0.03145859, -0.030995002]\n",
      "0.49038443 -1.2066728\n",
      "0.3835616438356164\n",
      "[-0.1149813  -0.030995    0.09089057  0.03145859  0.49038443]\n",
      "0.20992215\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:13,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(30, 105), (230, 249), (430, 469), (630, 650), (830, 886), (1030, 1078), (1230, 1278), (1430, 1453), (1630, 1657), (1830, 1865), (2030, 2060), (2230, 2399), (2430, 2460), (2630, 2799), (2830, 2860), (3030, 3199)]\n",
      "[0.36124215, -0.7817743, -1.0322014, -1.3061774, -1.5169894, -1.2642195, -1.1654935, -1.9331814, -1.4085691, -1.9271463, -0.27829963, -0.21966518, -0.27829963, -0.21966518, -0.27829963, -0.21966518]\n",
      "0.36124215 -1.9331814\n",
      "0.8307692307692308\n",
      "[-0.27829963 -0.21966518 -0.21966518 -0.21966518  0.36124215]\n",
      "0.23930632\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:15,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(31, 73), (134, 176), (237, 271), (340, 380), (443, 476), (546, 579), (649, 682), (752, 803), (855, 916), (958, 999), (1061, 1114), (1164, 1235), (1267, 1320), (1370, 1441), (1473, 1526), (1576, 1647), (1679, 1732), (1782, 1853)]\n",
      "[-2.684211, -2.684211, -2.1545157, -1.7040567, -2.4370456, -1.8213952, -1.8213952, -2.3020127, -1.9610484, -1.9174998, -0.9552623, -0.7830328, -0.9552623, -0.7830328, -0.9552623, -0.7830328, -0.9552623, -0.7830328]\n",
      "-0.7830328 -2.684211\n",
      "0.3939393939393939\n",
      "[-0.9552623 -0.7830328 -0.7830328 -0.7830328 -0.7830328]\n",
      "0.068891816\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:19,  2.74s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 11\u001b[0m     generated_output, log_prob \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_confidence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     model_forward \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(\n\u001b[1;32m     23\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39mcontext_ids\u001b[38;5;241m.\u001b[39mcuda(),\n\u001b[1;32m     24\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mcontext_mask\u001b[38;5;241m.\u001b[39mcuda(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m         output_unnormalized_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     29\u001b[0m     )\n\u001b[1;32m     31\u001b[0m cross_attentions \u001b[38;5;241m=\u001b[39m model_forward\u001b[38;5;241m.\u001b[39mcross_attentions\n",
      "File \u001b[0;32m~/FiD/src/model.py:65\u001b[0m, in \u001b[0;36mFiDT5.generate\u001b[0;34m(self, input_ids, attention_mask, max_length, output_confidence, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 65\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m sequence \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39msequences\n\u001b[1;32m     75\u001b[0m unsoftmaxed_distributions \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mscores\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/FiD/src/transformer_modules/generation_utils.py:1000\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    996\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_return_sequences has to be 1, but is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_return_sequences\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m when doing greedy search.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    997\u001b[0m         )\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;66;03m# greedy search\u001b[39;00m\n\u001b[0;32m-> 1000\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgreedy_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_sample_gen_mode:\n\u001b[1;32m   1013\u001b[0m     \u001b[38;5;66;03m# get probability distribution warper\u001b[39;00m\n\u001b[1;32m   1014\u001b[0m     logits_warper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(\n\u001b[1;32m   1015\u001b[0m         top_k\u001b[38;5;241m=\u001b[39mtop_k, top_p\u001b[38;5;241m=\u001b[39mtop_p, temperature\u001b[38;5;241m=\u001b[39mtemperature, num_beams\u001b[38;5;241m=\u001b[39mnum_beams\n\u001b[1;32m   1016\u001b[0m     )\n",
      "File \u001b[0;32m~/FiD/src/transformer_modules/generation_utils.py:1302\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1299\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   1301\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 1302\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1306\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   1310\u001b[0m     cur_len \u001b[38;5;241m=\u001b[39m cur_len \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/FiD/src/model.py:43\u001b[0m, in \u001b[0;36mFiDT5.forward\u001b[0;34m(self, input_ids, attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m attention_mask\u001b[38;5;241m.\u001b[39mview(attention_mask\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/FiD/src/transformer_modules/modeling_t5.py:1825\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_unnormalized_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1822\u001b[0m         decoder_attention_mask \u001b[38;5;241m=\u001b[39m decoder_attention_mask\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mfirst_device)\n\u001b[1;32m   1824\u001b[0m \u001b[38;5;66;03m# Decode\u001b[39;00m\n\u001b[0;32m-> 1825\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1826\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1827\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1828\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1829\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1830\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1834\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1835\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1836\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_unnormalized_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_unnormalized_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1837\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1839\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1841\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m decoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1843\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/FiD/src/transformer_modules/modeling_t5.py:1028\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_unnormalized_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1015\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m checkpoint(\n\u001b[1;32m   1016\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m   1017\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# past_key_value is always None with gradient checkpointing\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m     )\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1028\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1038\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_unnormalized_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_unnormalized_attentions\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;66;03m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1045\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/FiD/src/transformer_modules/modeling_t5.py:693\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, output_unnormalized_attentions, return_dict)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    691\u001b[0m     query_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 693\u001b[0m cross_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_unnormalized_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_unnormalized_attentions\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    707\u001b[0m \u001b[38;5;66;03m# clamp inf values to enable fp16 training\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/FiD/src/transformer_modules/modeling_t5.py:617\u001b[0m, in \u001b[0;36mT5LayerCrossAttention.forward\u001b[0;34m(self, hidden_states, key_value_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, query_length, output_attentions, output_unnormalized_attentions)\u001b[0m\n\u001b[1;32m    604\u001b[0m normed_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(hidden_states)\n\u001b[1;32m    605\u001b[0m attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mEncDecAttention(\n\u001b[1;32m    606\u001b[0m     normed_hidden_states,\n\u001b[1;32m    607\u001b[0m     mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    615\u001b[0m     output_unnormalized_attentions\u001b[38;5;241m=\u001b[39moutput_unnormalized_attentions\n\u001b[1;32m    616\u001b[0m )\n\u001b[0;32m--> 617\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    618\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m attention_output[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/torch/nn/modules/dropout.py:58\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/torch/nn/functional.py:1279\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(p))\n\u001b[0;32m-> 1279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, batch in tqdm(enumerate(dataloader_dev)):\n",
    "    (idx, labels, _, context_ids, context_mask) = batch\n",
    "            \n",
    "    # print(i)\n",
    "    \n",
    "    # if i in low_rouge_similarity_indices:\n",
    "    \n",
    "    print(i)\n",
    "    with torch.no_grad():\n",
    "\n",
    "        generated_output, log_prob = model.generate(\n",
    "                input_ids=context_ids.cuda(),\n",
    "                attention_mask=context_mask.cuda(),\n",
    "                do_sample=False,\n",
    "                max_length=150,\n",
    "                top_p=0.9,\n",
    "                temperature=1.0,\n",
    "                output_confidence=True,\n",
    "\n",
    "            )\n",
    "\n",
    "        model_forward = model.forward(\n",
    "            input_ids=context_ids.cuda(),\n",
    "            attention_mask=context_mask.cuda(),\n",
    "            # decoder_input_ids=labels.cuda(),\n",
    "            decoder_input_ids=generated_output.cuda(),\n",
    "            output_attentions=True,\n",
    "            output_unnormalized_attentions=True,\n",
    "        )\n",
    "\n",
    "    cross_attentions = model_forward.cross_attentions\n",
    "    stacked_forward_attentions = torch.cat(cross_attentions, dim=0)\n",
    "    msk = torch.reshape(context_mask, (1, context_mask.shape[1]*context_mask.shape[2])).cuda()\n",
    "\n",
    "    masked_stacked_forward_attentions = stacked_forward_attentions.masked_fill(msk == False, -10000.0)\n",
    "\n",
    "    avg_attn_matrix = torch.mean(masked_stacked_forward_attentions, dim=(0, 1)).cpu()\n",
    "    context_ids_reshaped = torch.reshape(context_ids, (1, context_ids.shape[1]*context_ids.shape[2]))\n",
    "    all_input_tokens = tokenizer.convert_ids_to_tokens(context_ids_reshaped[0])\n",
    "\n",
    "    start_pattern = ['▁title', ':', '▁context', ':']\n",
    "    end_pattern = ['</s>']\n",
    "\n",
    "    start_index_pattern = subfinder(all_input_tokens, start_pattern)\n",
    "    end_index_pattern = subfinder(all_input_tokens, end_pattern)\n",
    "\n",
    "    start_indices = [el[0] for el in start_index_pattern]\n",
    "    end_indices = [el[0] for el in end_index_pattern]\n",
    "\n",
    "    relevant_ranges = [(start_index, end_index - 1) for start_index, end_index in zip(start_indices, end_indices)]\n",
    "    print(relevant_ranges)\n",
    "    \n",
    "    mean_savgols = []\n",
    "    for relevant_range in relevant_ranges:\n",
    "        spliced_attn_matrix = avg_attn_matrix[:, relevant_range[0]:relevant_range[1]]\n",
    "\n",
    "        maxpool = torch.max(spliced_attn_matrix, axis=0).values.cpu().numpy()\n",
    "        minpool = torch.min(spliced_attn_matrix, axis=0).values.cpu().numpy()\n",
    "\n",
    "        m = maxpool\n",
    "        # m = maxpool - minpool\n",
    "        try:\n",
    "            savgol = scipy.signal.savgol_filter(m, 10, 3)\n",
    "\n",
    "        except ValueError:\n",
    "            try:\n",
    "                savgol = scipy.signal.savgol_filter(m, 5, 3)\n",
    "\n",
    "            except ValueError:\n",
    "                try:\n",
    "                    savgol = scipy.signal.savgol_filter(m, 3, 2)\n",
    "\n",
    "                except ValueError:\n",
    "                    try:\n",
    "                        savgol = scipy.signal.savgol_filter(m, 2, 1)\n",
    "\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            savgol = scipy.signal.savgol_filter(m, 1, 0)\n",
    "\n",
    "                        except ValueError:\n",
    "                            savgol = [-float('inf')]\n",
    "\n",
    "        mean_savgol = np.mean(savgol)\n",
    "\n",
    "        mean_savgols.append(mean_savgol)\n",
    "\n",
    "    passage_max_scores.append(max(mean_savgols))\n",
    "    passage_mean_scores.append(np.mean(mean_savgols))\n",
    "    print(mean_savgols)\n",
    "    \n",
    "    rouge_scores.append(rouge_matches[i][2])\n",
    "    log_probs.append(log_prob)\n",
    "    print(max(mean_savgols), min(mean_savgols))\n",
    "    print(rouge_matches[i][2])\n",
    "    \n",
    "    mean_savgols_np = np.array(mean_savgols)\n",
    "    topk_means_savgols = np.partition(mean_savgols_np, -topk_passages)[-topk_passages:]\n",
    "    \n",
    "    print(topk_means_savgols)\n",
    "    \n",
    "    mean_topk_mean_savgols = np.mean(topk_means_savgols)\n",
    "    std_topk_mean_savgols = np.std(topk_means_savgols)\n",
    "    \n",
    "    print(std_topk_mean_savgols)\n",
    "    \n",
    "    topk_passage_means.append(mean_topk_mean_savgols)\n",
    "    topk_passage_stdevs.append(std_topk_mean_savgols)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1c5b65-498f-4e00-b7fa-8f3184345685",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped_means = list(zip(log_probs, rouge_scores, topk_passage_means))\n",
    "zipped_stdevs = list(zip(log_probs, rouge_scores, topk_passage_stdevs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5277b8b7-a67e-4989-a7a5-7005a922cb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_passage_means = np.load(\"../numpy_drops/topk_passage_means_p09_t07.npy\")\n",
    "topk_passage_stdevs = np.load(\"../numpy_drops/topk_passage_stdevs_p09_t07.npy\")\n",
    "rouge_scores = [el[2] for el in rouge_matches]\n",
    "log_probs = [el[3].astype('float') for el in rouge_matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f12b3fd-8b1c-4f25-bd6a-3d9637fc681d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipped_means_stdevs = list(zip(rouge_scores, log_probs, topk_passage_means, topk_passage_stdevs))\n",
    "len(zipped_means_stdevs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f482ce83-ec14-45e6-9df8-26efdde35fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169\n",
      "217\n"
     ]
    }
   ],
   "source": [
    "rouge_threshold = 0.7\n",
    "\n",
    "corrects_rouge = [(el[1], el[2], el[3]) for el in zipped_means_stdevs if el[0] >= rouge_threshold]\n",
    "incorrects_rouge = [(el[1], el[2], el[3]) for el in zipped_means_stdevs if el[0] < rouge_threshold]\n",
    "\n",
    "print(len(corrects_rouge))\n",
    "print(len(incorrects_rouge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41493bc1-a25e-4188-b0d6-abd3228b12b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores_rouge = corrects_rouge + incorrects_rouge\n",
    "y_true_rouge = list(np.zeros(len(corrects_rouge)).astype(int)) + list(np.ones(len(incorrects_rouge)).astype(int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "263987d2-9d45-4fe0-bcb0-af27794cf7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.7571428571428571\n",
      "recall: 0.3136094674556213\n"
     ]
    }
   ],
   "source": [
    "threshold_output = 0.0001\n",
    "threshold_mean = -9.0\n",
    "threshold_stdev = 1.0\n",
    "\n",
    "label_scores = list(zip(y_true_rouge, y_scores_rouge))\n",
    "\n",
    "predicted_positive = [el for el in label_scores if (el[1][0] <= threshold_output and el[1][1] >= threshold_mean and el[1][2] <= threshold_stdev)]\n",
    "predicted_negative = [el for el in label_scores if el not in predicted_positive]\n",
    "\n",
    "true_positive = len([el for el in predicted_positive if el[0] == 0])\n",
    "false_positive = len([el for el in predicted_positive if el[0] == 1])\n",
    "\n",
    "true_negative = len([el for el in predicted_negative if el[0] == 1])\n",
    "false_negative = len([el for el in predicted_negative if el[0] == 0])\n",
    "\n",
    "precision = true_positive / (true_positive + false_positive)\n",
    "recall = true_positive / (true_positive + false_negative)\n",
    "\n",
    "\n",
    "print(f\"precision: {precision}\")\n",
    "print(f\"recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "685f0f07-4fb2-44a3-a2fb-95a5003211a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total examples: 386\n",
      "fraction allowed through: 0.18134715025906736\n"
     ]
    }
   ],
   "source": [
    "total_examples = len(predicted_positive) + len(predicted_negative)\n",
    "\n",
    "print(f\"total examples: {total_examples}\")\n",
    "\n",
    "allowed_through = true_positive + false_positive\n",
    "\n",
    "fraction_allowed_through = allowed_through / total_examples\n",
    "\n",
    "print(f\"fraction allowed through: {fraction_allowed_through}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f6898e-b83d-450a-8f62-e7c53c0e2075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03f02bd-d9f4-4438-b913-269d3aac9419",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d29417f-7f50-4f01-bb53-5a66c8d3c122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d01645b-0210-4ef7-bf0d-e2e74243387e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002b4d1e-78c1-4bea-b583-3ccf2ba52127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c8e32b-4676-41b8-b836-4702d2115d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd053e1-57aa-4cfd-9010-4dcf4bf92df4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9371215-21af-4e9c-9e3c-a545441cc39a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b66bbcd-b975-448a-917b-a9bf85040d75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe875ae7-7e47-4a7e-99d4-703223e18aac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aa82ce-4ad4-4e2f-80f8-f44de71ad22b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309581a7-b73b-4e49-b038-55c60cf91579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc3b479-8e1a-4c8b-8825-3850574536b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfa0bc9-e030-4a3c-b0be-8a98ee0aefe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302a0144-bdcb-4beb-943b-8997990830cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdev_threshold = 0.3\n",
    "rouge_threshold = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e937bbdd-0c7a-441f-8821-f7dbe3192886",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(zipped_stdevs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864ac097-95f7-4580-abaf-a783e7d2673a",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_zipped_stdevs = [el for el in zipped_stdevs if el[1] >= rouge_threshold]\n",
    "correct_zipped_stdevs_thresholded = [el for el in correct_zipped_stdevs if el[2] <= stdev_threshold]\n",
    "\n",
    "incorrect_zipped_stdevs = [el for el in zipped_stdevs if el[1] < rouge_threshold]\n",
    "incorrect_zipped_stdevs_thresholded = [el for el in zipped_stdevs if el[2] > stdev_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5008dc13-f847-46d1-86a6-6c944c097ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_zipped_means = [el for el in zipped_means if el[1] >= 0.7]\n",
    "correct_zipped_means_thresholded = [el for el in correct_zipped_means if el[2] >= 0.0]\n",
    "\n",
    "incorrect_zipped_means = [el for el in zipped_means if el[1] < 0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0cfc32-b1b8-40bf-a693-b5ba9b4fa921",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(correct_zipped_stdevs))\n",
    "print(len(incorrect_zipped_stdevs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8558c8e3-f6c2-4d46-8032-1a54cab5b53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(correct_zipped_stdevs_thresholded))\n",
    "print(len(incorrect_zipped_stdevs_thresholded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79bcd36-c3ad-441f-910a-9902dc8936b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8), facecolor=\"white\")\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "corrects_unzipped = list(zip(*correct_zipped_stdevs))\n",
    "corrects_unzipped_thresholded = list(zip(*correct_zipped_stdevs_thresholded))\n",
    "\n",
    "ax.scatter(list(range(len(corrects_unzipped[0]))), corrects_unzipped[0], color='red')\n",
    "ax.scatter(list(range(len(corrects_unzipped_thresholded[0]))), corrects_unzipped_thresholded[0], color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da7a2f5-a659-4285-ae58-56c87ae3fe4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7397c1e3-bd78-4710-8b89-56f46e34980a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dfa392-eecd-46da-98da-d267ae0d9f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db17088e-97f2-49e2-8d92-6290ebba64cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8486100d-1207-47f9-9c79-4bccc6aacba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8b6d36-1da3-41ae-8fbd-3eb8243f55fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ebcd85-a015-4585-ae6f-fda366e13d73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a3c933-4b3e-49bd-a804-645aeab9c2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc36fb02-f23a-4991-85be-cfde55022736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675654a2-dfe6-4fea-ad91-5abb9769ec05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69542a0f-33c7-42bf-a6f3-d6c4cdd6f1eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a165f6-f241-4cea-8f43-df891af717fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(rouge_scores, topk_passage_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91089894-46e4-4b7f-8a5d-93ff5851587a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(rouge_scores, topk_passage_stdevs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36d1848-fc63-42d0-ae3a-09479de43ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(log_probs, rouge_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d132a46-fe17-4f88-a162-d9fa95aeab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rouge_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89db1074-dbf8-46da-a172-983e06d5dbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(topk_passage_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10aeed0-1c7e-4d8f-a521-bc16931652e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8), facecolor=\"white\")\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(rouge_scores, max_savgols)\n",
    "ax.set_xlabel(\"rouge score\")\n",
    "ax.set_ylabel(\"unnormalised average passage score\")\n",
    "ax.set_title(\"max passage score vs rouge similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9618ab-0781-4a2f-af2d-88debebb3d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8), facecolor=\"white\")\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(log_probs, max_savgols)\n",
    "ax.set_xlabel(\"log prob score\")\n",
    "ax.set_ylabel(\"unnormalised average passage score\")\n",
    "ax.set_title(\"log prob score vs rouge similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7da166f-f9c7-4bea-a50c-c0657219426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8), facecolor=\"white\")\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.scatter(list(range(len(min_savgols_high_similarity))), min_savgols_high_similarity, color = 'red', label = 'max score')\n",
    "ax.scatter(list(range(len(max_savgols_high_similarity))), max_savgols_high_similarity, color = 'blue', label = 'min score')\n",
    "ax.set_xlabel(\"example\")\n",
    "ax.set_ylabel(\"unnormalised attention score\")\n",
    "ax.set_title(\"rouge > 0.7\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab5d886-f2d5-4497-96e4-709bd4f25acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8), facecolor=\"white\")\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.scatter(list(range(len(min_savgols_low_similarity))), min_savgols_low_similarity, color = 'red', label = 'max passage score')\n",
    "ax.scatter(list(range(len(max_savgols_low_similarity))), max_savgols_low_similarity, color = 'blue', label = 'min passage score')\n",
    "\n",
    "ax.set_xlabel(\"example\")\n",
    "ax.set_ylabel(\"unnormalised attention score\")\n",
    "ax.set_title(\"rouge < 0.3\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8a87d3-94a3-4fff-bea9-2afbf4a41468",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8), facecolor=\"white\")\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.scatter(list(range(len(min_savgols_high_similarity))), min_savgols_high_similarity, color = 'red', label = 'high rouge score')\n",
    "ax.scatter(list(range(len(max_savgols_high_similarity))), max_savgols_high_similarity, color = 'red', label = 'high rouge score')\n",
    "\n",
    "ax.scatter(list(range(len(min_savgols_low_similarity))), min_savgols_low_similarity, color = 'blue', label = 'low rouge score')\n",
    "ax.scatter(list(range(len(max_savgols_low_similarity))), max_savgols_low_similarity, color = 'blue', label = 'low rouge score')\n",
    "\n",
    "ax.set_xlabel(\"example\")\n",
    "ax.set_ylabel(\"unnormalised attention score\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba1fc47-2324-4e99-8b7d-999a24cd65e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8), facecolor=\"white\")\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.scatter(list(range(len(max_savgols_high_similarity))), max_savgols_high_similarity, color = 'purple', label = 'max high similarity')\n",
    "ax.scatter(list(range(len(max_savgols_low_similarity))), max_savgols_low_similarity, color = 'orange', label = 'max low similarity')\n",
    "\n",
    "ax.set_xlabel(\"example\")\n",
    "ax.set_ylabel(\"unnormalised attention score\")\n",
    "ax.set_title(\"max passage scores, high and low similarity\")\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09739aea-c509-4606-98f9-3c3dba665743",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(dataloader_dev):\n",
    "    (idx, labels, _, context_ids, context_mask) = batch\n",
    "    \n",
    "    if i in example_indices:\n",
    "        \n",
    "        print(i)\n",
    "        with torch.no_grad():\n",
    "            model_forward = model.forward(\n",
    "                input_ids=context_ids.cuda(),\n",
    "                attention_mask=context_mask.cuda(),\n",
    "                decoder_input_ids=labels.cuda(),\n",
    "                output_attentions=True,\n",
    "                output_unnormalized_attentions=True,\n",
    "            )\n",
    "\n",
    "        cross_attentions = model_forward.cross_attentions\n",
    "        stacked_forward_attentions = torch.cat(cross_attentions, dim=0)\n",
    "        msk = torch.reshape(context_mask, (1, context_mask.shape[1]*context_mask.shape[2])).cuda()\n",
    "\n",
    "        masked_stacked_forward_attentions = stacked_forward_attentions.masked_fill(msk == False, -10000.0)\n",
    "\n",
    "        avg_attn_matrix = torch.mean(masked_stacked_forward_attentions, dim=(0, 1)).cpu()\n",
    "        context_ids_reshaped = torch.reshape(context_ids, (1, context_ids.shape[1]*context_ids.shape[2]))\n",
    "        all_input_tokens = tokenizer.convert_ids_to_tokens(context_ids_reshaped[0])\n",
    "\n",
    "\n",
    "\n",
    "        start_pattern = ['▁title', ':', '▁context', ':']\n",
    "        end_pattern = ['</s>']\n",
    "\n",
    "        start_index_pattern = subfinder(all_input_tokens, start_pattern)\n",
    "        end_index_pattern = subfinder(all_input_tokens, end_pattern)\n",
    "\n",
    "        start_indices = [el[0] for el in start_index_pattern]\n",
    "        end_indices = [el[0] for el in end_index_pattern]\n",
    "\n",
    "        relevant_ranges = [(start_index, end_index - 1) for start_index, end_index in zip(start_indices, end_indices)]\n",
    "    \n",
    "        print(relevant_ranges)\n",
    "        for relevant_range in relevant_ranges:\n",
    "            spliced_attn_matrix = avg_attn_matrix[:, relevant_range[0]:relevant_range[1]]\n",
    "            \n",
    "        \n",
    "            maxpool = torch.max(spliced_attn_matrix, axis=0).values.cpu().numpy()\n",
    "            minpool = torch.min(spliced_attn_matrix, axis=0).values.cpu().numpy()\n",
    "\n",
    "            m = maxpool\n",
    "            savgol = scipy.signal.savgol_filter(m, 10, 3)\n",
    "\n",
    "            print(np.mean(savgol))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2453cee0-0b6c-4d64-b531-ab944762c982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ae3ac34-18e7-40c5-b70b-89181c9f01d2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualise question-stripped passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c4a84c-57f6-4bb3-a732-38ba13fd6c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model_forward = model.forward(\n",
    "    input_ids=context_ids.cuda(),\n",
    "    attention_mask=context_mask.cuda(),\n",
    "    decoder_input_ids=generated_output.cuda(),\n",
    "    # decoder_input_ids=labels.cuda(),\n",
    "    output_attentions=True,\n",
    "    output_unnormalized_attentions=True,\n",
    "    )\n",
    "\n",
    "cross_attentions = model_forward.cross_attentions\n",
    "stacked_forward_attentions = torch.cat(cross_attentions, dim=0)\n",
    "msk = torch.reshape(context_mask, (1, context_mask.shape[1]*context_mask.shape[2])).cuda()\n",
    "\n",
    "masked_stacked_forward_attentions = stacked_forward_attentions.masked_fill(msk == False, -10000.0)\n",
    "\n",
    "avg_attn_matrix = torch.mean(masked_stacked_forward_attentions, dim=(0, 1)).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132d50dc-7d37-439f-a920-284b1b4bbca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subfinder(mylist, pattern):\n",
    "    matches = []\n",
    "    for i in range(len(mylist)):\n",
    "        if mylist[i] == pattern[0] and mylist[i:i+len(pattern)] == pattern:\n",
    "            matches.append((i + len(pattern), pattern))\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581f9bb5-1bbb-4918-89a5-47e4ef165d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_attn_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88199dc4-129f-48b1-8ae8-5e4ae05fb2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "passage_len = context_mask.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f4e644-df38-46e0-8624-8b05820a1906",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_ids_reshaped = torch.reshape(context_ids, (1, context_ids.shape[1]*context_ids.shape[2]))\n",
    "context_ids_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3eae98-b8f2-45e5-8910-47346b6f0a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_input_tokens = tokenizer.convert_ids_to_tokens(context_ids_reshaped[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69cece1-6ed3-4720-8836-15c702088bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_pattern = ['▁title', ':', '▁context', ':']\n",
    "end_pattern = ['</s>']\n",
    "\n",
    "start_index_pattern = subfinder(all_input_tokens, start_pattern)\n",
    "end_index_pattern = subfinder(all_input_tokens, end_pattern)\n",
    "\n",
    "start_indices = [el[0] for el in start_index_pattern]\n",
    "end_indices = [el[0] for el in end_index_pattern]\n",
    "\n",
    "# remove end of sentence token\n",
    "relevant_ranges = [(start_index, end_index - 1) for start_index, end_index in zip(start_indices, end_indices)]\n",
    "\n",
    "relevant_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de7152f-7e05-41c4-835b-9822e7c2c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 20), facecolor=\"white\")\n",
    "\n",
    "for i in range(len(relevant_ranges)):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    relevant_range = relevant_ranges[i]\n",
    "    spliced_attn_matrix = avg_attn_matrix[:, relevant_range[0]:relevant_range[1]]\n",
    "    spliced_attn_matrix_np = spliced_attn_matrix.numpy()\n",
    "    \n",
    "    np.save(f'example_matrix_{i}.npy', spliced_attn_matrix_np)\n",
    "    im = plt.imshow(spliced_attn_matrix, cmap=plt.get_cmap('hot'), aspect='auto', vmin=-10, vmax=2)\n",
    "    \n",
    "    plt.xlabel('passage token')\n",
    "    plt.ylabel('ground truth token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed4776d-60a0-409e-ab47-b035b14694b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 15), facecolor=\"white\")\n",
    "savgols = []\n",
    "for i in range(len(relevant_ranges)):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    relevant_range = relevant_ranges[i]\n",
    "    spliced_attn_matrix = avg_attn_matrix[:, relevant_range[0]:relevant_range[1]]\n",
    "    \n",
    "    maxpool = torch.max(spliced_attn_matrix, axis=0).values.cpu().numpy()\n",
    "    minpool = torch.min(spliced_attn_matrix, axis=0).values.cpu().numpy()\n",
    "    \n",
    "    # m = maxpool - minpool\n",
    "    m = maxpool\n",
    "    # print(np.mean(m))\n",
    "    savgol = scipy.signal.savgol_filter(m, 5, 3)\n",
    "    print(np.mean(savgol))\n",
    "    savgols.append(savgol)\n",
    "    \n",
    "    plt.plot(m)\n",
    "    plt.plot(savgol, label='savitzky-golay cubic interpolation')\n",
    "    plt.legend()\n",
    "    plt.xlabel('passage_token')\n",
    "    plt.ylabel('unnormalised max attention')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4784ba5-1e87-4d56-a341-9038cdca2425",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_decoded_passage_tokens = tokenizer.convert_ids_to_tokens(context_ids_reshaped[0])\n",
    "decoded_labels = tokenizer.convert_ids_to_tokens(generated_output[0])\n",
    "\n",
    "i = 0\n",
    "\n",
    "relevant_range = relevant_ranges[i]\n",
    "spliced_attn_matrix = avg_attn_matrix[:, relevant_range[0]:relevant_range[1]]\n",
    "relevant_passage_tokens = all_decoded_passage_tokens[relevant_range[0]:relevant_range[1]]\n",
    "\n",
    "# spliced_attn_matrix = np.load('example_matrix_1.npy')\n",
    "\n",
    "fig = plt.figure(figsize=(20, 20), facecolor=\"white\")\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "im = ax.imshow(spliced_attn_matrix, cmap=plt.get_cmap('hot'), aspect='auto', vmin=-10, vmax=2)\n",
    "\n",
    "xticks = ax.set_xticks(range(len(relevant_passage_tokens)), rotation=90)\n",
    "xlabels = ax.set_xticklabels(relevant_passage_tokens, rotation=90)\n",
    "\n",
    "yticks = ax.set_yticks(range(len(decoded_labels)), rotation=90)\n",
    "ylabels = ax.set_yticklabels(decoded_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7600d38d-456d-4237-af08-c52b84b36c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 10\n",
    "\n",
    "peaks, properties = find_peaks(savgols[i], width=3)\n",
    "plt.plot(savgols[i])\n",
    "plt.scatter(list(peaks), [savgols[i][idx] for idx in list(peaks)], color='red')\n",
    "\n",
    "plt.vlines(x=peaks, ymin=savgols[i][peaks] - properties[\"prominences\"],\n",
    "           ymax = savgols[i][peaks], color = \"C1\")\n",
    "\n",
    "plt.hlines(y=properties[\"width_heights\"], xmin=properties[\"left_ips\"],\n",
    "           xmax=properties[\"right_ips\"], color = \"C1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e262d7-62e3-4bd2-8903-64bd5ad6a6d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6670f54-d07d-4aea-96d6-9fc5acc5d351",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualise layer-head averaged cross-attention matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87c239d-a541-4571-a418-a98584decf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL RELEVANT PASSAGES\n",
    "fig = plt.figure(figsize=(20, 10), facecolor=\"white\")\n",
    "ax = fig.add_subplot()\n",
    "#ax.imshow(averaged_attention_matrix[:, :], cmap='hot', interpolation='nearest')\n",
    "im = ax.imshow(avg_attn_matrix.cpu().numpy(), cmap=plt.get_cmap('hot'), aspect='auto', vmin=-10, vmax=0)\n",
    "fig.colorbar(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7601608-1d05-4ade-bcff-c8e57984b894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY FIRST PASSAGE RELEVANT \n",
    "fig = plt.figure(figsize=(20, 10), facecolor=\"white\")\n",
    "ax = fig.add_subplot()\n",
    "#ax.imshow(averaged_attention_matrix[:, :], cmap='hot', interpolation='nearest')\n",
    "im = ax.imshow(avg_attn_matrix.cpu().numpy(), cmap=plt.get_cmap('hot'), aspect='auto', vmin=-10, vmax=0)\n",
    "fig.colorbar(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de61125c-6750-4a4e-b51c-08d030d70459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL PASSAGES IRRELEVANT\n",
    "fig = plt.figure(figsize=(20, 10), facecolor=\"white\")\n",
    "ax = fig.add_subplot()\n",
    "#ax.imshow(averaged_attention_matrix[:, :], cmap='hot', interpolation='nearest')\n",
    "im = ax.imshow(avg_attn_matrix.cpu().numpy(), cmap=plt.get_cmap('hot'), aspect='auto', vmin=-10, vmax=0)\n",
    "fig.colorbar(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c028080-4b8b-4168-aa96-cdf62571b79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIRST PASSAGE RELEVANT\n",
    "passage_len = context_mask.shape[2]\n",
    "start = 1\n",
    "end = 2\n",
    "\n",
    "\n",
    "decoded_passage_tokens = tokenizer.convert_ids_to_tokens(context_ids_reshaped[0][(start*passage_len):(end*passage_len)])\n",
    "decoded_labels = tokenizer.convert_ids_to_tokens(labels[0])\n",
    "\n",
    "fig = plt.figure(figsize=(20, 20), facecolor=\"white\")\n",
    "ax = fig.add_subplot(111)\n",
    "passage_1_sector = avg_attn_matrix[:, (start*passage_len):(end*passage_len)]\n",
    "im = ax.imshow(passage_1_sector, cmap=plt.get_cmap('hot'), aspect='auto', vmin=-10, vmax=0)\n",
    "\n",
    "ax.set_xticks(range(passage_len), rotation=90)\n",
    "ax.set_xticklabels(decoded_passage_tokens, rotation=90)\n",
    "\n",
    "ax.set_yticks(range(len(labels[0])), rotation=90)\n",
    "ax.set_yticklabels(decoded_labels)\n",
    "\n",
    "fig.colorbar(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee404de-5893-41a3-a113-75927b1cafb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe4549cd-3213-4a2c-931b-5f986b1b5ad9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Obtaining the generative output score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdbd42d-d37f-4ab4-a6c7-846448bb788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11aed56-410e-40d8-b59f-033b9968f49f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b037e084-19a1-48f3-ae96-5c91a268cc7c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Figure out prevalence of very confident, correct vs incorrect answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e47d33e-78e6-4944-b98b-ba8c74aaebdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# only one context vector\n",
    "\n",
    "exact_match_log_probabilities = []\n",
    "incorrect_log_probabilities = []\n",
    "exact_match_answers = []\n",
    "\n",
    "for i, batch in tqdm(enumerate(dataloader)):\n",
    "    \n",
    "    (idx, _, _, context_ids, context_mask) = batch\n",
    "    sequences = model.generate(\n",
    "                input_ids=context_ids.cuda(),\n",
    "                attention_mask=context_mask.cuda(),\n",
    "                max_length=100,\n",
    "                return_dict_in_generate=True,\n",
    "                output_scores=True\n",
    "            ).sequences\n",
    "\n",
    "    \n",
    "    for k, o in enumerate(sequences):\n",
    "        ans = tokenizer.decode(o, skip_special_tokens=True)\n",
    "        gold = eval_dataset.get_example(idx[k])['answers']\n",
    "        score = ems(ans, gold)\n",
    "        #print(score)\n",
    "        # total += 1\n",
    "        # exactmatch.append(score)\n",
    "#         print(\"model generated output:\")\n",
    "#         print(ans)\n",
    "\n",
    "#         print(\"\")\n",
    "#         print(\"ground truth:\")\n",
    "#         print(gold) \n",
    "\n",
    "    # print(\"extracting negative log probability ...\")\n",
    "    log_probability = model.obtain_log_generated_probability(\n",
    "        input_ids=context_ids.cuda(),\n",
    "        attention_mask=context_mask.cuda(),\n",
    "        max_length=100\n",
    "\n",
    "    )\n",
    "    \n",
    "    if score == True:\n",
    "        exact_match_log_probabilities.append(log_probability.cpu().numpy())\n",
    "        exact_match_answers.append(ans)\n",
    "#         if len(exact_match_log_probabilities) >= 5:\n",
    "#             print(\"exceeded five exact matches\")\n",
    "        \n",
    "#         if len(exact_match_log_probabilities) >= 10:\n",
    "#             print(\"exceeded ten exact matches\")\n",
    "    \n",
    "    else:\n",
    "        incorrect_log_probabilities.append(log_probability.cpu().numpy())\n",
    "        \n",
    "    if i >= 0:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1deddd-3169-4188-9b5b-a8a94124935f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from local\n",
    "exact_match_log_probabilities = np.load(\"../numpy_drops/exact_matches_dev.npy\")\n",
    "incorrect_log_probabilities = np.load(\"../numpy_drops/incorrects_dev.npy\")\n",
    "rouge_match_log_probabilities = np.load(\"../numpy_drops/rouge_matches_dev.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c77fd37-fccb-4104-9821-28cf9dcb8cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../numpy_drops/rouge_similarity_answers_dev_sampling\", \"rb\") as f:\n",
    "    rouge_matches = pickle.load(f)\n",
    "\n",
    "len(rouge_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd961250-dc44-4e56-9058-bd246d9bd816",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([el for el in rouge_matches if el[2] == 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cea20b9-3cb7-4b68-9160-0fa62f038669",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped_rouge = list(zip(rouge_matches, rouge_match_log_probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fc44e1-b259-4e0c-a8bd-195de57a5613",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"rouge match distribution\")\n",
    "print(len(rouge_match_log_probabilities))\n",
    "print(np.mean(rouge_match_log_probabilities))\n",
    "print(np.std(rouge_match_log_probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1208a3a3-d29b-40bd-9a04-ae03d4796166",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"exact match distribution\")\n",
    "print(len(exact_match_log_probabilities))\n",
    "print(np.mean(exact_match_log_probabilities))\n",
    "print(np.std(exact_match_log_probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8495c9bf-8ef1-471a-8d46-f2e6ad59210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"incorrect match distribution\")\n",
    "print(len(incorrect_log_probabilities))\n",
    "print(np.mean(incorrect_log_probabilities))\n",
    "print(np.std(incorrect_log_probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87139496-6e89-450d-94c9-8d0f2c2e9193",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8), facecolor=\"white\")\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(list(range(len(incorrect_log_probabilities))), incorrect_log_probabilities, label=\"incorrects\")\n",
    "ax.scatter(list(range(len(rouge_match_log_probabilities))), rouge_match_log_probabilities, color=\"red\", label=\"rouge corrects\")\n",
    "ax.scatter(list(range(len(exact_match_log_probabilities))), exact_match_log_probabilities, color=\"orange\", label=\"exact matches\")\n",
    "ax.set_ylabel(\"log_sum_prob\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec08277-0e30-4971-94e6-86b6a872406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped_rouge = list(zip(rouge_matches, rouge_match_log_probabilities))\n",
    "\n",
    "inexact_matches = [el for el in zipped_rouge if el[0][2] != 1.0]\n",
    "\n",
    "inexact_match_log_probabilities = list(zip(*inexact_matches))[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bc0f25-fa69-4e88-8ce9-746295fd090a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rouge-l correctness\n",
    "corrects_rouge = list(rouge_match_log_probabilities)\n",
    "incorrects_rouge = list(incorrect_log_probabilities)\n",
    "\n",
    "y_scores_rouge = corrects_rouge + incorrects_rouge\n",
    "y_true_rouge = list(np.zeros(len(corrects_rouge)).astype(int)) + list(np.ones(len(incorrects_rouge)).astype(int))\n",
    "\n",
    "# exact match correctness\n",
    "corrects_exact = list(exact_match_log_probabilities)\n",
    "incorrects_exact = list(incorrect_log_probabilities) + list(inexact_match_log_probabilities)\n",
    "\n",
    "y_scores_exact = corrects_exact + incorrects_exact\n",
    "y_true_exact = list(np.zeros(len(corrects_exact)).astype(int)) + list(np.ones(len(incorrects_exact)).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537ed91b-8f9d-4158-99e3-049c50489fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corrects_rouge) + len(incorrects_rouge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8189a4-a5f7-4b31-bcb0-158962edc5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.003\n",
    "\n",
    "label_scores = list(zip(y_true_rouge, y_scores_rouge))\n",
    "\n",
    "predicted_positive = [el for el in label_scores if el[1] <= threshold]\n",
    "predicted_negative = [el for el in label_scores if el[1] > threshold]\n",
    "\n",
    "true_positive = len([el for el in predicted_positive if el[0] == 0])\n",
    "false_positive = len([el for el in predicted_positive if el[0] == 1])\n",
    "\n",
    "true_negative = len([el for el in predicted_negative if el[0] == 1])\n",
    "false_negative = len([el for el in predicted_negative if el[0] == 0])\n",
    "\n",
    "precision = true_positive / (true_positive + false_positive)\n",
    "recall = true_positive / (true_positive + false_negative)\n",
    "\n",
    "\n",
    "print(f\"precision: {precision}\")\n",
    "print(f\"recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5f672f-681e-4e70-85a6-27afb7506faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_examples = len(rouge_match_log_probabilities) + len(incorrect_log_probabilities)\n",
    "\n",
    "print(f\"total examples: {total_examples}\")\n",
    "\n",
    "allowed_through = true_positive + false_positive\n",
    "\n",
    "fraction_allowed_through = allowed_through / total_examples\n",
    "\n",
    "print(f\"fraction allowed through: {fraction_allowed_through}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b72f03-3f7f-4d3c-9fd9-3fc6d6687ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6da0450-96b4-4ee8-ba8e-709d724fddb4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### PR curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5223f024-a1ac-4928-9d6c-ab13cdc70a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_p_and_r(y_true, y_pred, thresholds):\n",
    "    \n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        label_scores = list(zip(y_true, y_pred))\n",
    "\n",
    "        predicted_positive = [el for el in label_scores if el[1] <= threshold]\n",
    "        predicted_negative = [el for el in label_scores if el[1] > threshold]\n",
    "\n",
    "        true_positive = len([el for el in predicted_positive if el[0] == 0])\n",
    "        false_positive = len([el for el in predicted_positive if el[0] == 1])\n",
    "\n",
    "        true_negative = len([el for el in predicted_negative if el[0] == 1])\n",
    "        false_negative = len([el for el in predicted_negative if el[0] == 0])\n",
    "\n",
    "        precision = true_positive / (true_positive + false_positive)\n",
    "        recall = true_positive / (true_positive + false_negative)\n",
    "\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "    \n",
    "    return precisions, recalls\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a32b98-c750-4518-b5f0-dce910658acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0, 1, 101)\n",
    "\n",
    "precisions_rouge, recalls_rouge = obtain_p_and_r(y_true_rouge, y_scores_rouge, thresholds)\n",
    "precisions_exact, recalls_exact = obtain_p_and_r(y_true_exact, y_scores_exact, thresholds)\n",
    "\n",
    "precisions_rouge = [1.0] + precisions_rouge + [0.0]\n",
    "recalls_rouge = [0.0] + recalls_rouge + [1.0]\n",
    "\n",
    "precisions_exact = [1.0] + precisions_exact + [0.0]\n",
    "recalls_exact = [0.0] + recalls_exact + [1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1ac5b4-9dce-4e62-b36a-bb0188028225",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8), facecolor=\"white\")\n",
    "fig.suptitle(\"Rouge-L PR curve\", fontsize=16)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.step(recalls_rouge, precisions_rouge, label=\"rouge-l confidences\", where='post')\n",
    "plt.axhline(1 - sum(y_true_rouge) / len(y_true_rouge), xmin=0.0, xmax=0.95, linestyle='--', color=\"red\", label=\"rouge-l coin flip\")\n",
    "ax.set_xlim([0.0, 1.05])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel(\"recall\")\n",
    "ax.set_ylabel(\"precision\")\n",
    "ax.text(0.1, 0.1, \"auc: {:.4f}\".format(auc(recalls_rouge, precisions_rouge)), bbox=dict(facecolor='white', alpha=0.5))\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fdd5ad-df53-4cee-aba3-049d1d3cd821",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8), facecolor=\"white\")\n",
    "fig.suptitle(\"Exact match PR curve\", fontsize=16)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# ax.plot(recalls_exact, precisions_exact)\n",
    "ax.step(recalls_exact, precisions_exact, label=\"exact match confidences\", where='post')\n",
    "plt.axhline(1 - sum(y_true_exact) / len(y_true_exact), xmin=0.0, xmax=0.95, linestyle='--', color=\"red\", label=\"exact match coin flip\")\n",
    "ax.set_xlim([0.0, 1.05])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel(\"recall\")\n",
    "ax.set_ylabel(\"precision\")\n",
    "ax.text(0.15, 0.5, \"auc: {:.4f}\".format(auc(recalls_exact, precisions_exact)), bbox=dict(facecolor='white', alpha=0.5))\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cafa4fb-c1ff-4a92-ba32-23c85d43f8d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a86be57b-521f-459b-979c-d2a63e7f73ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### inspect some generated sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e041e50f-dea9-4299-b9fb-d159379b4f91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, batch in enumerate(dataloader):\n",
    "    (idx, labels, _, context_ids, context_mask) = batch\n",
    "    for j in range(context_ids.shape[1]):\n",
    "\n",
    "            print(\"====\")\n",
    "            print(j)\n",
    "            context = tokenizer.decode(context_ids[0][j])\n",
    "            print(context)\n",
    "            if j >= 0:\n",
    "                break\n",
    "    \n",
    "    if i > 0:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb1ceef-71da-4082-a04a-4b12be24e3b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "[el for el in rouge_matches if el[2] == 1.0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920976d8-2fbd-444b-8b12-b071bf58f9b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07f7edc5-2c72-45f6-81b7-b97c716fc69b",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3127b2d5-c7df-41cd-8b59-2a28498cbcb6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Obtain example generated vs ground truth outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764c5d4b-2536-4871-9f90-baeaf5668f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only one context vector\n",
    "for i, batch in enumerate(dataloader):\n",
    "    \n",
    "    if i == 7:\n",
    "        print(f\"training example: {i}\")\n",
    "        (idx, _, _, context_ids, context_mask) = batch\n",
    "        sequences = model.generate(\n",
    "                    input_ids=context_ids.cuda(),\n",
    "                    attention_mask=context_mask.cuda(),\n",
    "                    max_length=10,\n",
    "                    return_dict_in_generate=True,\n",
    "                    output_scores=True\n",
    "                ).sequences\n",
    "\n",
    "        print(sequences)\n",
    "        for k, o in enumerate(sequences):\n",
    "            ans = tokenizer.decode(o, skip_special_tokens=True)\n",
    "            gold = eval_dataset.get_example(idx[k])['answers']\n",
    "            score = ems(ans, gold)\n",
    "            #print(score)\n",
    "            # total += 1\n",
    "            # exactmatch.append(score)\n",
    "            print(\"model generated output:\")\n",
    "            print(ans)\n",
    "\n",
    "            print(\"\")\n",
    "            print(\"ground truth:\")\n",
    "            print(gold) \n",
    "        \n",
    "        print(\"extracting negative log probability ...\")\n",
    "        log_probability = model.obtain_log_generated_probability(\n",
    "            input_ids=context_ids.cuda(),\n",
    "            attention_mask=context_mask.cuda(),\n",
    "            max_length=10\n",
    "            \n",
    "        )\n",
    "        \n",
    "        print(score)\n",
    "        \n",
    "        print(log_probability)\n",
    "        \n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fc799d-b658-43a9-97de-e529d4250ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = torch.nn.Softmax(dim=1)\n",
    "total_log_prob = 0\n",
    "for i in range(len(outputs.scores)):\n",
    "    print(torch.log(torch.max(softmax(outputs.scores[i]))))\n",
    "    total_log_prob -= torch.log(torch.max(softmax(outputs.scores[i])))\n",
    "\n",
    "total_log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f52b13-94a2-4043-b07d-1195e05255dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f66611c-d8a9-42d5-83e6-298ec5f025bf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Comparing tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3bea34-717f-4adc-8713-5fc46c51c760",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = transformers.AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "t5_tokenizer = transformers.T5Tokenizer.from_pretrained('t5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86de111e-f083-4537-bba7-cefb87414e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = \"Welcome to the HuggingFace Library\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25ba5fc-1856-4ee2-a02c-1b4cb2a32e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenized = bert_tokenizer(input_sequence, return_tensors='pt')\n",
    "t5_tokenized = t5_tokenizer(input_sequence, return_tensors='pt')\n",
    "\n",
    "print(bert_tokenized.input_ids)\n",
    "print(\"===\")\n",
    "print(t5_tokenized.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ada9e88-a19c-46e9-a479-950b78a2bfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bert_tokenizer.decode(bert_tokenized.input_ids[0]))\n",
    "print(\"===\")\n",
    "print(t5_tokenizer.decode(t5_tokenized.input_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b59e9e3-c830-431d-a41b-bb4dc8568b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer.convert_ids_to_tokens(bert_tokenized.input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35906e4-9b0f-453e-be19-04572a2196a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_tokenizer.convert_ids_to_tokens(t5_tokenized.input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d841dcf5-03f4-45b3-833c-f08068432109",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn((2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b9d800-96a1-4530-a0aa-a5fafa60720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = torch.tensor([[True, False, True], [False, True, False]])\n",
    "msk2 = torch.tensor([[True, False, True, True]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfd9dc2-991a-434f-a0bf-cfa7c5e3513d",
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94242788-d831-4b1a-9af2-2765cddcfc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.masked_fill(msk2 == 0, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f450d1b-f2b9-49e1-b9c3-f14d8afe1216",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061ace48-4a47-4b81-a1e5-d981cea097c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04227314-f4aa-42ad-b782-1ee2659743c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer.encode(\"summarise: I am originally from siberia, where the sky is green\", return_tensors=\"pt\")  # Batch size 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8f6f04-729c-49b7-b10f-89bd1c1d9577",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(input_ids, \n",
    "                          return_dict_in_generate=True, \n",
    "                          output_scores=True, \n",
    "                          num_beams=1,\n",
    "                          do_sample=True,\n",
    "                          top_k=3,\n",
    "                          temperature=1.0\n",
    "                          )\n",
    "\n",
    "\n",
    "outputs.sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cef76a-d40a-4ea9-b6cc-b8035bcabd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = outputs.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7b8f71-a4fe-4f36-a761-b121555bbf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.topk(scores[2][0], k=3).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36df9872-3d05-43d1-a5a9-07ec73c84db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba22c04-7255-498a-b559-f34889a1ddd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = torch.nn.Softmax(dim=1)\n",
    "softmax(scores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5575ef-ca7a-4992-b176-776642064456",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[4][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b588c5e-4194-47c3-971b-6710975106e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[4][0][sequence[0][5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae743d0-70bf-4333-a75d-42cb2bb20ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(scores[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14990a15-097f-4181-81aa-8c1875a3615d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = []\n",
    "for i in range(len(scores)):\n",
    "    sfx = softmax(scores[i])\n",
    "    ans.append(sfx[0][sequence[0][i + 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a342be2-5679-40d8-8088-cc9c666854b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([0, 0, 1, 1, 1])\n",
    "y_scores = np.array([0.1, 0.4, 0.35, 0.8, 0.9])\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_true, y_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb91721e-2bd4-4656-9218-09bee9cce740",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.35\n",
    "\n",
    "label_scores = list(zip(y_true, y_scores))\n",
    "\n",
    "predicted_positive = [el for el in label_scores if el[1] >= threshold]\n",
    "predicted_negative = [el for el in label_scores if el[1] < threshold]\n",
    "\n",
    "true_positive = len([el for el in predicted_positive if el[0] == 1])\n",
    "false_positive = len([el for el in predicted_positive if el[0] == 0])\n",
    "\n",
    "true_negative = len([el for el in predicted_negative if el[0] == 0])\n",
    "false_negative = len([el for el in predicted_negative if el[0] == 1])\n",
    "\n",
    "precision = true_positive / (true_positive + false_positive)\n",
    "recall = true_positive / (true_positive + false_negative)\n",
    "\n",
    "print(precision)\n",
    "print(recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7bea12-48c2-46f7-b0c7-3c1030b4fe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae284ea-dd71-47fd-86f2-fb20e9278528",
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6adafa-5ea4-4f84-9f4a-36e77be9dfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa9316a-c101-408f-9be3-2449dc815016",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
